{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a85d5d2",
   "metadata": {},
   "source": [
    "# SPAM DETECTION USING NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06057789",
   "metadata": {},
   "source": [
    " Download the nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51ce342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:42:44.987002Z",
     "start_time": "2023-09-22T12:42:36.182313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027bce0",
   "metadata": {},
   "source": [
    "Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdc33bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:43:02.731170Z",
     "start_time": "2023-09-22T12:43:02.248579Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16dee889",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:43:09.007179Z",
     "start_time": "2023-09-22T12:43:08.958257Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/91741/Downloads/SMSSpamCollection.tsv\",sep=\"\\t\",header=None) \n",
    "pd.set_option(\"display.max_colwidth\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e40818f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:43:15.381671Z",
     "start_time": "2023-09-22T12:43:15.350197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  \\\n",
       "0   ham   \n",
       "1  spam   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                     1  \n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...  \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though  \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.  \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab29b5",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a0492e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:43:42.801817Z",
     "start_time": "2023-09-22T12:43:42.793267Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns=[\"labels\",\"total text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1bf798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:44:01.304962Z",
     "start_time": "2023-09-22T12:44:01.292265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>total text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels  \\\n",
       "0    ham   \n",
       "1   spam   \n",
       "2    ham   \n",
       "3    ham   \n",
       "4    ham   \n",
       "\n",
       "                                                                                            total text  \n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...  \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though  \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.  \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16440e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:44:09.144727Z",
     "start_time": "2023-09-22T12:44:09.129153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5568, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f7c97c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:44:14.654560Z",
     "start_time": "2023-09-22T12:44:14.638424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4822\n",
       "spam     746\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66283b9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:44:22.046394Z",
     "start_time": "2023-09-22T12:44:22.036297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5568 entries, 0 to 5567\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   labels      5568 non-null   object\n",
      " 1   total text  5568 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ebf1bfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:44:28.974580Z",
     "start_time": "2023-09-22T12:44:28.946557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>total text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5568</td>\n",
       "      <td>5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4822</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels              total text\n",
       "count    5568                    5568\n",
       "unique      2                    5165\n",
       "top       ham  Sorry, I'll call later\n",
       "freq     4822                      30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445c5dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:44:36.201004Z",
     "start_time": "2023-09-22T12:44:36.186174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels        0\n",
       "total text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "474b08ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:44:42.288533Z",
     "start_time": "2023-09-22T12:44:42.280461Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"labels\"]=data[\"labels\"].replace(\"ham\",\"notspam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f1454a",
   "metadata": {},
   "source": [
    "REMOVE PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab97bb51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:45:32.118271Z",
     "start_time": "2023-09-22T12:45:32.046030Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def punc(text):\n",
    "    textnonpunc=\"\".join([char for char in text if char not in string.punctuation])\n",
    "    return textnonpunc\n",
    "data[\"clean_text\"]=data[\"total text\"].apply(lambda x : punc(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e4959e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:45:39.685333Z",
     "start_time": "2023-09-22T12:45:39.666104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>total text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notspam</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notspam</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notspam</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notspam</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels  \\\n",
       "0  notspam   \n",
       "1     spam   \n",
       "2  notspam   \n",
       "3  notspam   \n",
       "4  notspam   \n",
       "\n",
       "                                                                                            total text  \\\n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                                                                            clean_text  \n",
       "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...  \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...  \n",
       "2                                          Nah I dont think he goes to usf he lives around here though  \n",
       "3                          Even my brother is not like to speak with me They treat me like aids patent  \n",
       "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a9c82",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51edd2cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:46:11.462807Z",
     "start_time": "2023-09-22T12:46:11.397602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>total text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenised text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notspam</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notspam</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notspam</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notspam</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels  \\\n",
       "0  notspam   \n",
       "1     spam   \n",
       "2  notspam   \n",
       "3  notspam   \n",
       "4  notspam   \n",
       "\n",
       "                                                                                            total text  \\\n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                                                                            clean_text  \\\n",
       "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
       "2                                          Nah I dont think he goes to usf he lives around here though   \n",
       "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
       "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                                                                        tokenised text  \n",
       "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...  \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...  \n",
       "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]  \n",
       "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]  \n",
       "4                                                           [i, have, a, date, on, sunday, with, will]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def token(text):\n",
    "    tokens=re.split('\\W+',text)\n",
    "    return tokens\n",
    "data[\"tokenised text\"]=data.clean_text.apply(lambda x : token(x.lower()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894d7b3",
   "metadata": {},
   "source": [
    "Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5663d378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:46:45.499501Z",
     "start_time": "2023-09-22T12:46:45.324143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>total text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenised text</th>\n",
       "      <th>body_text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notspam</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notspam</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notspam</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notspam</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels  \\\n",
       "0  notspam   \n",
       "1     spam   \n",
       "2  notspam   \n",
       "3  notspam   \n",
       "4  notspam   \n",
       "\n",
       "                                                                                            total text  \\\n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                                                                            clean_text  \\\n",
       "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
       "2                                          Nah I dont think he goes to usf he lives around here though   \n",
       "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
       "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                                                                        tokenised text  \\\n",
       "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...   \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...   \n",
       "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
       "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]   \n",
       "4                                                           [i, have, a, date, on, sunday, with, will]   \n",
       "\n",
       "                                                                                      body_text_nostop  \n",
       "0  [ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
       "2                                                 [nah, dont, think, goes, usf, lives, around, though]  \n",
       "3                                              [even, brother, like, speak, treat, like, aids, patent]  \n",
       "4                                                                                       [date, sunday]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words(\"english\")\n",
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "data['body_text_nostop'] = data['tokenised text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fef904d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:46:56.130240Z",
     "start_time": "2023-09-22T12:46:56.122119Z"
    }
   },
   "outputs": [],
   "source": [
    " data.drop(columns=[\"total text\",'clean_text','tokenised text'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c766a676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:47:08.264498Z",
     "start_time": "2023-09-22T12:47:08.248362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notspam</td>\n",
       "      <td>[ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, promise, wonderful, blessing, times]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 08452810075over18s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notspam</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notspam</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notspam</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels  \\\n",
       "0  notspam   \n",
       "1     spam   \n",
       "2  notspam   \n",
       "3  notspam   \n",
       "4  notspam   \n",
       "\n",
       "                                                                                                                                                  body_text_nostop  \n",
       "0                                 [ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, promise, wonderful, blessing, times]  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 08452810075over18s]  \n",
       "2                                                                                                             [nah, dont, think, goes, usf, lives, around, though]  \n",
       "3                                                                                                          [even, brother, like, speak, treat, like, aids, patent]  \n",
       "4                                                                                                                                                   [date, sunday]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\",200)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d1620",
   "metadata": {},
   "source": [
    "Lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d5ffaf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:47:33.773360Z",
     "start_time": "2023-09-22T12:47:32.197116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>body_text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notspam</td>\n",
       "      <td>[ive, searching, right, word, thank, breather, promise, wont, take, help, granted, fulfil, promise, wonderful, blessing, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 08452810075over18s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notspam</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notspam</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aid, patent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>notspam</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels  \\\n",
       "0  notspam   \n",
       "1     spam   \n",
       "2  notspam   \n",
       "3  notspam   \n",
       "4  notspam   \n",
       "\n",
       "                                                                                                                                              body_text_lemmatized  \n",
       "0                                   [ive, searching, right, word, thank, breather, promise, wont, take, help, granted, fulfil, promise, wonderful, blessing, time]  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receive, entry, questionstd, txt, ratetcs, apply, 08452810075over18s]  \n",
       "2                                                                                                                [nah, dont, think, go, usf, life, around, though]  \n",
       "3                                                                                                           [even, brother, like, speak, treat, like, aid, patent]  \n",
       "4                                                                                                                                                   [date, sunday]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wn = WordNetLemmatizer()\n",
    "def lemmatizing(tokenized_text):\n",
    "    texts = [wn.lemmatize(char) for char in tokenized_text]\n",
    "    return texts\n",
    "\n",
    "data['body_text_lemmatized'] = data['body_text_nostop'].apply(lambda x: lemmatizing(x))\n",
    "data.drop(columns=[\"body_text_nostop\"],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeebb51",
   "metadata": {},
   "source": [
    "Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1554ef0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:48:06.078652Z",
     "start_time": "2023-09-22T12:48:05.839170Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector=CountVectorizer(analyzer=lemmatizing)\n",
    "x_counts=count_vector.fit_transform(data[\"body_text_lemmatized\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f40268aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:48:15.399923Z",
     "start_time": "2023-09-22T12:48:15.379874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5568, 8912)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "129115b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:48:29.837773Z",
     "start_time": "2023-09-22T12:48:29.788341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "008704050406\n",
      "0089my\n",
      "0121\n",
      "01223585236\n",
      "01223585334\n",
      "0125698789\n",
      "02\n",
      "020603\n",
      "0207\n",
      "02070836089\n",
      "02072069400\n",
      "02073162414\n",
      "02085076972\n",
      "020903\n",
      "021\n",
      "050703\n",
      "0578\n",
      "06\n",
      "060505\n",
      "061104\n",
      "07008009200\n",
      "07046744435\n",
      "07090201529\n",
      "07090298926\n",
      "07099833605\n",
      "071104\n",
      "07123456789\n",
      "0721072\n",
      "07732584351\n",
      "07734396839\n",
      "07742676969\n",
      "07753741225\n",
      "0776xxxxxxx\n",
      "07786200117\n",
      "077xxx\n",
      "078\n",
      "07801543489\n",
      "07808\n",
      "07808247860\n",
      "07808726822\n",
      "07815296484\n",
      "07821230901\n",
      "0784987\n",
      "0789xxxxxxx\n",
      "0794674629107880867867\n",
      "0796xxxxxx\n",
      "07973788240\n",
      "07xxxxxxxxx\n",
      "0800\n",
      "08000407165\n",
      "08000776320\n",
      "08000839402\n",
      "08000930705\n",
      "08000938767\n",
      "08001950382\n",
      "08002888812\n",
      "08002986030\n",
      "08002986906\n",
      "08002988890\n",
      "08006344447\n",
      "0808\n",
      "08081263000\n",
      "08081560665\n",
      "0825\n",
      "0844\n",
      "08448350055\n",
      "08448714184\n",
      "0845\n",
      "08450542832\n",
      "08452810071\n",
      "08452810073\n",
      "08452810075over18s\n",
      "0870\n",
      "08700621170150p\n",
      "08701213186\n",
      "08701237397\n",
      "08701417012\n",
      "08701417012150p\n",
      "0870141701216\n",
      "087016248\n",
      "08701752560\n",
      "087018728737\n",
      "0870241182716\n",
      "08702490080\n",
      "08702840625\n",
      "08702840625comuk\n",
      "08704439680\n",
      "08704439680tscs\n",
      "08706091795\n",
      "0870737910216yrs\n",
      "08707500020\n",
      "08707509020\n",
      "0870753331018\n",
      "08707808226\n",
      "08708034412\n",
      "08708800282\n",
      "08709222922\n",
      "08709501522\n",
      "0870k\n",
      "087104711148\n",
      "08712101358\n",
      "08712103738\n",
      "0871212025016\n",
      "08712300220\n",
      "087123002209am7pm\n",
      "08712317606\n",
      "08712400200\n",
      "08712400603\n",
      "08712402050\n",
      "08712402578\n",
      "08712402779\n",
      "08712402902\n",
      "08712402972\n",
      "08712404000\n",
      "08712405020\n",
      "08712405022\n",
      "08712460324\n",
      "08712460324nat\n",
      "08712466669\n",
      "0871277810710pmin\n",
      "0871277810810\n",
      "0871277810910pmin\n",
      "087143423992stop\n",
      "087147123779am7pm\n",
      "08714712379\n",
      "08714712388\n",
      "08714712394\n",
      "08714712412\n",
      "08714714011\n",
      "08714719523\n",
      "08715203028\n",
      "08715203649\n",
      "08715203652\n",
      "08715203656\n",
      "08715203677\n",
      "08715203685\n",
      "08715203694\n",
      "08715205273\n",
      "08715500022\n",
      "08715705022\n",
      "08717111821\n",
      "08717168528\n",
      "08717205546\n",
      "08717507382\n",
      "08717507711\n",
      "08717509990\n",
      "08717890890\n",
      "08717895698\n",
      "08717898035\n",
      "08718711108\n",
      "08718720201\n",
      "08718723815\n",
      "08718725756\n",
      "08718726270\n",
      "08718726270150gbpmtmsg18\n",
      "08718726970\n",
      "08718726971\n",
      "08718726978\n",
      "087187272008\n",
      "08718727868\n",
      "08718727870\n",
      "08718729755\n",
      "08718729758\n",
      "08718730555\n",
      "08718730666\n",
      "08718738001\n",
      "08718738002\n",
      "08718738034\n",
      "08719180219\n",
      "08719180248\n",
      "08719181259\n",
      "08719181503\n",
      "08719181513\n",
      "08719839835\n",
      "08719899217\n",
      "08719899229\n",
      "08719899230\n",
      "09041940223\n",
      "09050000301\n",
      "09050000332\n",
      "09050000460\n",
      "09050000555\n",
      "09050000878\n",
      "09050000928\n",
      "09050001295\n",
      "09050001808\n",
      "09050002311\n",
      "09050003091\n",
      "09050005321\n",
      "09050090044\n",
      "09050280520\n",
      "09053750005\n",
      "09056242159\n",
      "09057039994\n",
      "09058091854\n",
      "09058091870\n",
      "09058094454\n",
      "09058094455\n",
      "09058094507\n",
      "09058094565\n",
      "09058094583\n",
      "09058094594\n",
      "09058094597\n",
      "09058094599\n",
      "09058095107\n",
      "09058095201\n",
      "09058097189\n",
      "09058097218\n",
      "09058098002\n",
      "09058099801\n",
      "09061104276\n",
      "09061104283\n",
      "09061209465\n",
      "09061213237\n",
      "09061221061\n",
      "09061221066\n",
      "09061701444\n",
      "09061701461\n",
      "09061701851\n",
      "09061701939\n",
      "09061702893\n",
      "09061743386\n",
      "09061743806\n",
      "09061743810\n",
      "09061743811\n",
      "09061744553\n",
      "09061749602\n",
      "09061790121\n",
      "09061790125\n",
      "09061790126\n",
      "09063440451\n",
      "09063442151\n",
      "09063458130\n",
      "0906346330\n",
      "09064011000\n",
      "09064012103\n",
      "09064012160\n",
      "09064015307\n",
      "09064017295\n",
      "09064017305\n",
      "09064018838\n",
      "09064019014\n",
      "09064019788\n",
      "09065069120\n",
      "09065069154\n",
      "09065171142stopsms08\n",
      "09065171142stopsms08718727870150ppm\n",
      "09065174042\n",
      "09065394514\n",
      "09065394973\n",
      "09065989180\n",
      "09065989182\n",
      "09066350750\n",
      "09066358152\n",
      "09066358361\n",
      "09066361921\n",
      "09066362206\n",
      "09066362220\n",
      "09066362231\n",
      "09066364311\n",
      "09066364349\n",
      "09066364589\n",
      "09066368327\n",
      "09066368470\n",
      "09066368753\n",
      "09066380611\n",
      "09066382422\n",
      "09066612661\n",
      "09066649731from\n",
      "09066660100\n",
      "09071512432\n",
      "09071512433\n",
      "09071517866\n",
      "09077818151\n",
      "09090204448\n",
      "09090900040\n",
      "09094100151\n",
      "09094646631\n",
      "09094646899\n",
      "09095350301\n",
      "09096102316\n",
      "09099725823\n",
      "09099726395\n",
      "09099726429\n",
      "09099726481\n",
      "09099726553\n",
      "09111030116\n",
      "09111032124\n",
      "09701213186\n",
      "0anetworks\n",
      "1\n",
      "10\n",
      "100\n",
      "1000\n",
      "10000\n",
      "100000\n",
      "1000call\n",
      "100603\n",
      "100psms\n",
      "1010\n",
      "1013\n",
      "101mega\n",
      "1030\n",
      "10803\n",
      "10am\n",
      "10am7pm\n",
      "10am9pm\n",
      "10k\n",
      "10p\n",
      "10pmin\n",
      "10ppm\n",
      "10th\n",
      "11\n",
      "1120\n",
      "113\n",
      "1131\n",
      "11414\n",
      "1146\n",
      "1148\n",
      "116\n",
      "1172\n",
      "118pmsg\n",
      "11mths\n",
      "12\n",
      "120\n",
      "12000pes\n",
      "1205\n",
      "121\n",
      "1225\n",
      "123\n",
      "1230\n",
      "125\n",
      "1250\n",
      "125gift\n",
      "128\n",
      "12hours\n",
      "12hrs\n",
      "12mths\n",
      "12price\n",
      "13\n",
      "130\n",
      "131004\n",
      "1327\n",
      "13404\n",
      "139\n",
      "140\n",
      "1405\n",
      "140ppm\n",
      "145\n",
      "1450\n",
      "146tf150p\n",
      "14thmarch\n",
      "150\n",
      "1500\n",
      "150ea\n",
      "150morefrmmob\n",
      "150msg\n",
      "150mtmsgrcvd18\n",
      "150p\n",
      "150pday\n",
      "150perweeksub\n",
      "150perwksub\n",
      "150pm\n",
      "150pmeg\n",
      "150pmin\n",
      "150pmmorefrommobile2bremovedmobypobox734ls27yf\n",
      "150pmsg\n",
      "150pmsgrcvd\n",
      "150pmsgrcvdhgsuite3422landsroww1j6hl\n",
      "150pmt\n",
      "150pmtmsg\n",
      "150pmtmsgrcvd18\n",
      "150ppermesssubscription\n",
      "150ppm\n",
      "150ppmpobox10183bhamb64xe\n",
      "150ppmsg\n",
      "150prcvd\n",
      "150psms\n",
      "150ptext\n",
      "150ptone\n",
      "150pw\n",
      "150pwk\n",
      "150rcvd\n",
      "150week\n",
      "150wk\n",
      "151\n",
      "1526\n",
      "153\n",
      "15541\n",
      "15pmin\n",
      "16\n",
      "1680\n",
      "169\n",
      "16only\n",
      "177\n",
      "18\n",
      "180\n",
      "181104\n",
      "1843\n",
      "186\n",
      "18only\n",
      "18ptxt\n",
      "18yrs\n",
      "195\n",
      "1956669\n",
      "1appledayno\n",
      "1childish\n",
      "1cup\n",
      "1da\n",
      "1er\n",
      "1hanuman\n",
      "1his\n",
      "1hr\n",
      "1im\n",
      "1lemondayno\n",
      "1mcflyall\n",
      "1million\n",
      "1minmobsmore\n",
      "1minmobsmorelkpobox177hp51fl\n",
      "1minmoremobsemspobox45po139wa\n",
      "1month\n",
      "1pm\n",
      "1st\n",
      "1st4terms\n",
      "1stchoicecouk\n",
      "1stone\n",
      "1tulsi\n",
      "1u\n",
      "1unbreakable\n",
      "1winaweek\n",
      "1winawk\n",
      "1x150pwk\n",
      "1yf\n",
      "2\n",
      "20\n",
      "200\n",
      "2000\n",
      "20000\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2025050\n",
      "20f\n",
      "20m12aq\n",
      "20p\n",
      "20pmin\n",
      "21\n",
      "211104\n",
      "215\n",
      "21870000hi\n",
      "21m\n",
      "21st\n",
      "22\n",
      "220cm2\n",
      "23\n",
      "2309\n",
      "230ish\n",
      "24\n",
      "241\n",
      "241004\n",
      "247mp\n",
      "24hrs\n",
      "24m\n",
      "24th\n",
      "25\n",
      "250\n",
      "250k\n",
      "255\n",
      "25f\n",
      "25p\n",
      "260305\n",
      "261004\n",
      "261104\n",
      "2667\n",
      "26th\n",
      "2703\n",
      "27603\n",
      "28\n",
      "2814032\n",
      "285\n",
      "28days\n",
      "28th\n",
      "28thfebtcs\n",
      "290305\n",
      "29100\n",
      "29m\n",
      "2b\n",
      "2bajarangabali\n",
      "2bold\n",
      "2c\n",
      "2channel\n",
      "2day\n",
      "2daylove\n",
      "2docdplease\n",
      "2end\n",
      "2exit\n",
      "2ez\n",
      "2getha\n",
      "2geva\n",
      "2go\n",
      "2godid\n",
      "2gthr\n",
      "2hook\n",
      "2hrs\n",
      "2i\n",
      "2im\n",
      "2kbsubject\n",
      "2marrow\n",
      "2moro\n",
      "2morow\n",
      "2morro\n",
      "2morrow\n",
      "2morrowxxxx\n",
      "2mro\n",
      "2mrw\n",
      "2mwen\n",
      "2naughty\n",
      "2nd\n",
      "2nhite\n",
      "2nights\n",
      "2nite\n",
      "2nitetell\n",
      "2optout\n",
      "2optoutd3wv\n",
      "2p\n",
      "2police\n",
      "2px\n",
      "2rcv\n",
      "2stop\n",
      "2stoptx\n",
      "2stoptxt\n",
      "2u\n",
      "2u2\n",
      "2untamed\n",
      "2watershd\n",
      "2waxsto\n",
      "2when\n",
      "2wks\n",
      "2wt\n",
      "2wu\n",
      "2years\n",
      "2yr\n",
      "2yrs\n",
      "3\n",
      "30\n",
      "300\n",
      "3000\n",
      "300603\n",
      "300603tcsbcm4235wc1n3xxcallcost150ppmmobilesvary\n",
      "300p\n",
      "3030\n",
      "30apr\n",
      "30pptxt\n",
      "30th\n",
      "31\n",
      "3100\n",
      "310303\n",
      "311004\n",
      "31pmsg150p\n",
      "32000\n",
      "3230\n",
      "32323\n",
      "326\n",
      "32f\n",
      "330\n",
      "3350\n",
      "3365\n",
      "350\n",
      "3510i\n",
      "35p\n",
      "3650\n",
      "36504\n",
      "3680\n",
      "3680offer\n",
      "373\n",
      "3750\n",
      "375max\n",
      "38\n",
      "391784\n",
      "399\n",
      "3aj\n",
      "3cover\n",
      "3d\n",
      "3days\n",
      "3db\n",
      "3g\n",
      "3gbp\n",
      "3hrs\n",
      "3lions\n",
      "3lp\n",
      "3maruti\n",
      "3miles\n",
      "3mins\n",
      "3mobile\n",
      "3optical\n",
      "3pound\n",
      "3qxj9\n",
      "3rd\n",
      "3sentiment\n",
      "3u\n",
      "3unkempt\n",
      "3uz\n",
      "3wife\n",
      "3wk\n",
      "3wks\n",
      "3x\n",
      "3xx\n",
      "4\n",
      "40\n",
      "400\n",
      "400minscall\n",
      "402\n",
      "4041\n",
      "40411\n",
      "40533\n",
      "40gb\n",
      "40mph\n",
      "415\n",
      "41685\n",
      "41782\n",
      "420\n",
      "42049\n",
      "4217\n",
      "42478\n",
      "42810\n",
      "430\n",
      "434\n",
      "44\n",
      "4403ldnw1a7rw18\n",
      "447797706009\n",
      "447801259231\n",
      "447per\n",
      "448712404000please\n",
      "449050000301\n",
      "449071512431\n",
      "449month\n",
      "45\n",
      "450\n",
      "450p\n",
      "450ppw\n",
      "450pw\n",
      "45239\n",
      "46\n",
      "47\n",
      "4712\n",
      "4742\n",
      "48\n",
      "4882\n",
      "48922\n",
      "49557\n",
      "4a\n",
      "4brekkie\n",
      "4cook\n",
      "4d\n",
      "4eva\n",
      "4few\n",
      "4fil\n",
      "4get\n",
      "4give\n",
      "4got\n",
      "4goten\n",
      "4info\n",
      "4jx\n",
      "4lux\n",
      "4mths\n",
      "4my\n",
      "4o\n",
      "4pavanaputra\n",
      "4press\n",
      "4rowdy\n",
      "4some1\n",
      "4tctxt\n",
      "4th\n",
      "4the\n",
      "4thnovbehind\n",
      "4txt120p\n",
      "4txt120\n",
      "4u\n",
      "4ui\n",
      "4utxt\n",
      "4w\n",
      "4ward\n",
      "4wrd\n",
      "4years\n",
      "5\n",
      "50\n",
      "500\n",
      "5000\n",
      "500000\n",
      "505060\n",
      "50award\n",
      "50p\n",
      "515\n",
      "515pm\n",
      "5226\n",
      "5249\n",
      "526\n",
      "528\n",
      "530\n",
      "532\n",
      "54\n",
      "542\n",
      "545\n",
      "5903\n",
      "5digital\n",
      "5free\n",
      "5ful\n",
      "5gardener\n",
      "5gently\n",
      "5i\n",
      "5ish\n",
      "5k\n",
      "5min\n",
      "5mls\n",
      "5month\n",
      "5p\n",
      "5pm\n",
      "5sankatmochan\n",
      "5terror\n",
      "5th\n",
      "5wb\n",
      "5we\n",
      "5wkg\n",
      "5wq\n",
      "5years\n",
      "6\n",
      "600\n",
      "6031\n",
      "60400thousadi\n",
      "60p\n",
      "60pmin\n",
      "61200\n",
      "61610\n",
      "62220cncl\n",
      "6230\n",
      "62468\n",
      "62735\n",
      "630\n",
      "63miles\n",
      "645\n",
      "645pm\n",
      "650\n",
      "6669\n",
      "67441233\n",
      "68866\n",
      "69101\n",
      "69200\n",
      "69669\n",
      "69696\n",
      "69698\n",
      "69855\n",
      "6986618\n",
      "69876\n",
      "69888\n",
      "69888nyt\n",
      "69911\n",
      "69969\n",
      "69988\n",
      "6cruel\n",
      "6days\n",
      "6hl\n",
      "6housemaid\n",
      "6hrs\n",
      "6ish\n",
      "6missed\n",
      "6months\n",
      "6pm\n",
      "6ramaduth\n",
      "6romantic\n",
      "6th\n",
      "6times\n",
      "6wu\n",
      "6zf\n",
      "7\n",
      "700\n",
      "71\n",
      "725\n",
      "7250\n",
      "7250i\n",
      "730\n",
      "730ish\n",
      "730pm\n",
      "731\n",
      "74355\n",
      "750\n",
      "75000\n",
      "7548\n",
      "7634\n",
      "7684\n",
      "7732584351\n",
      "78\n",
      "786\n",
      "7876150ppm\n",
      "78pmin\n",
      "79\n",
      "7am\n",
      "7cfca1a\n",
      "7children\n",
      "7ish\n",
      "7mahaveer\n",
      "7oz\n",
      "7pm\n",
      "7romantic\n",
      "7shy\n",
      "7th\n",
      "7ws\n",
      "7zs\n",
      "8\n",
      "80\n",
      "800\n",
      "8000930705\n",
      "80062\n",
      "8007\n",
      "80082\n",
      "80086\n",
      "80122300pwk\n",
      "80155\n",
      "80160\n",
      "80182\n",
      "8027\n",
      "80488\n",
      "80488biz\n",
      "80608\n",
      "8077\n",
      "80878\n",
      "81010\n",
      "81151\n",
      "81303\n",
      "81618\n",
      "816183\n",
      "82242\n",
      "82277\n",
      "82277unsub\n",
      "82324\n",
      "82468\n",
      "830\n",
      "83021\n",
      "83039\n",
      "83049\n",
      "83110\n",
      "83118\n",
      "83222\n",
      "83332please\n",
      "83338\n",
      "83355\n",
      "83370\n",
      "83383\n",
      "83435\n",
      "83600\n",
      "83738\n",
      "84\n",
      "84025\n",
      "84122\n",
      "84128\n",
      "84128custcare\n",
      "84199\n",
      "84484\n",
      "85\n",
      "850\n",
      "85023\n",
      "85069\n",
      "85222\n",
      "85233\n",
      "8552\n",
      "85555\n",
      "86021\n",
      "861\n",
      "863\n",
      "864233\n",
      "86688\n",
      "86888\n",
      "87021\n",
      "87066\n",
      "87070\n",
      "87077\n",
      "87121\n",
      "87131\n",
      "8714714\n",
      "87239\n",
      "87575\n",
      "8800\n",
      "88039\n",
      "88039skilgmetscs087147403231winawkage16\n",
      "88066\n",
      "88088\n",
      "88222\n",
      "8830\n",
      "88600\n",
      "88800\n",
      "8883\n",
      "88877\n",
      "88877free\n",
      "88888\n",
      "89034\n",
      "89070\n",
      "89080\n",
      "89105\n",
      "89123\n",
      "89545\n",
      "89555\n",
      "89693\n",
      "89938\n",
      "8am\n",
      "8attractive\n",
      "8ball\n",
      "8hr\n",
      "8lb\n",
      "8lovable\n",
      "8neighbour\n",
      "8o\n",
      "8pm\n",
      "8th\n",
      "8wp\n",
      "9\n",
      "900\n",
      "9061100010\n",
      "9153\n",
      "924\n",
      "92h\n",
      "930\n",
      "945\n",
      "946\n",
      "95pax\n",
      "96\n",
      "97n7qp\n",
      "98321561\n",
      "9996\n",
      "9ae\n",
      "9am\n",
      "9am11pm\n",
      "9decent\n",
      "9funny\n",
      "9ja\n",
      "9pm\n",
      "9t\n",
      "9th\n",
      "9yt\n",
      "a\n",
      "a21\n",
      "a30\n",
      "aa\n",
      "aah\n",
      "aaniye\n",
      "aaooooright\n",
      "aathilove\n",
      "aathiwhere\n",
      "ab\n",
      "abbey\n",
      "abdomen\n",
      "abeg\n",
      "abelu\n",
      "aberdeen\n",
      "abi\n",
      "ability\n",
      "abiola\n",
      "abj\n",
      "able\n",
      "abnormally\n",
      "aboutas\n",
      "abroad\n",
      "absence\n",
      "absolutely\n",
      "abstract\n",
      "abt\n",
      "abta\n",
      "aburo\n",
      "abuse\n",
      "abuser\n",
      "ac\n",
      "academic\n",
      "acc\n",
      "accent\n",
      "accenture\n",
      "accept\n",
      "access\n",
      "accessible\n",
      "accidant\n",
      "accident\n",
      "accidentally\n",
      "accommodation\n",
      "accommodationvouchers\n",
      "accomodate\n",
      "accomodations\n",
      "accordin\n",
      "accordingly\n",
      "accordinglyor\n",
      "account\n",
      "accounting\n",
      "accumulation\n",
      "achanammarakheshqatar\n",
      "ache\n",
      "achieve\n",
      "acid\n",
      "acknowledgement\n",
      "acl03530150pm\n",
      "acnt\n",
      "acoentry41\n",
      "across\n",
      "acsmsrewards\n",
      "act\n",
      "acted\n",
      "actin\n",
      "acting\n",
      "action\n",
      "activ8\n",
      "activate\n",
      "active\n",
      "activity\n",
      "actor\n",
      "actual\n",
      "actually\n",
      "acwicmb3cktz8r74\n",
      "ad\n",
      "adam\n",
      "add\n",
      "addamsfa\n",
      "added\n",
      "addicted\n",
      "addie\n",
      "adding\n",
      "address\n",
      "addressull\n",
      "adewale\n",
      "adi\n",
      "adjustable\n",
      "admin\n",
      "administrator\n",
      "admirer\n",
      "admission\n",
      "admit\n",
      "admiti\n",
      "adore\n",
      "adoring\n",
      "adp\n",
      "adress\n",
      "adrian\n",
      "adrink\n",
      "adsense\n",
      "adult\n",
      "advance\n",
      "adventure\n",
      "adventuring\n",
      "advice\n",
      "advise\n",
      "advising\n",
      "advisor\n",
      "aeronautics\n",
      "aeroplane\n",
      "afew\n",
      "affair\n",
      "affection\n",
      "affectionate\n",
      "affectionsamp\n",
      "affidavit\n",
      "afford\n",
      "afghanistan\n",
      "afraid\n",
      "africa\n",
      "african\n",
      "aft\n",
      "afternon\n",
      "afternoon\n",
      "afterwards\n",
      "aftr\n",
      "ag\n",
      "againcall\n",
      "againloving\n",
      "agalla\n",
      "age\n",
      "age16\n",
      "age16150ppermesssubscription\n",
      "age23\n",
      "agency\n",
      "agent\n",
      "agesring\n",
      "agidhane\n",
      "aging\n",
      "ago\n",
      "agocusoon\n",
      "agree\n",
      "agreen\n",
      "ah\n",
      "aha\n",
      "ahead\n",
      "ahgee\n",
      "ahhh\n",
      "ahhhhjust\n",
      "ahmad\n",
      "ahnow\n",
      "ahold\n",
      "ahsen\n",
      "ahthe\n",
      "ahwhat\n",
      "aid\n",
      "aig\n",
      "aight\n",
      "aint\n",
      "air\n",
      "air1\n",
      "airport\n",
      "airtel\n",
      "aiya\n",
      "aiyah\n",
      "aiyar\n",
      "aiyo\n",
      "ajith\n",
      "ak\n",
      "aka\n",
      "akonlonely\n",
      "al\n",
      "alaikkumpride\n",
      "alaipayuthe\n",
      "albi\n",
      "album\n",
      "albumquite\n",
      "alcohol\n",
      "aldrine\n",
      "alert\n",
      "alertfrom\n",
      "aletter\n",
      "alex\n",
      "alexs\n",
      "alfie\n",
      "algarve\n",
      "algebra\n",
      "algorithm\n",
      "ali\n",
      "alian\n",
      "alibi\n",
      "alive\n",
      "alivebetter\n",
      "allah\n",
      "allahmeet\n",
      "allahrakhesh\n",
      "allalo\n",
      "allday\n",
      "alle\n",
      "allo\n",
      "allow\n",
      "allowed\n",
      "allows\n",
      "alls\n",
      "almost\n",
      "alone\n",
      "along\n",
      "alot\n",
      "already\n",
      "alreadysabarish\n",
      "alright\n",
      "alrightokay\n",
      "alrite\n",
      "alritehave\n",
      "also\n",
      "alsoor\n",
      "alter\n",
      "alternativehope\n",
      "although\n",
      "alwa\n",
      "always\n",
      "alwys\n",
      "am\n",
      "amanda\n",
      "amazing\n",
      "ambitious\n",
      "ambrithmaduraimet\n",
      "american\n",
      "ami\n",
      "amigo\n",
      "amk\n",
      "ammaelife\n",
      "ammo\n",
      "amnow\n",
      "among\n",
      "amongst\n",
      "amount\n",
      "amp\n",
      "amplikater\n",
      "amrca\n",
      "amrita\n",
      "amt\n",
      "amused\n",
      "amx\n",
      "amy\n",
      "an\n",
      "ana\n",
      "anal\n",
      "analysis\n",
      "anand\n",
      "anderson\n",
      "andor\n",
      "andre\n",
      "andres\n",
      "andrewsboy\n",
      "andros\n",
      "angel\n",
      "angry\n",
      "animal\n",
      "animation\n",
      "anjie\n",
      "anjolas\n",
      "anna\n",
      "annie\n",
      "anniversary\n",
      "annoncement\n",
      "announced\n",
      "announcement\n",
      "annoyin\n",
      "annoying\n",
      "anonymous\n",
      "anot\n",
      "another\n",
      "ansr\n",
      "answer\n",
      "answered\n",
      "answerin\n",
      "answering\n",
      "answr\n",
      "antelope\n",
      "anthony\n",
      "anti\n",
      "antibiotic\n",
      "anybody\n",
      "anybodys\n",
      "anyhow\n",
      "anymore\n",
      "anyone\n",
      "anyones\n",
      "anyplaces\n",
      "anythiing\n",
      "anythin\n",
      "anything\n",
      "anythings\n",
      "anythingtomorrow\n",
      "anytime\n",
      "anyway\n",
      "anyways\n",
      "anywhere\n",
      "aom\n",
      "apart\n",
      "apartment\n",
      "ape\n",
      "apeshit\n",
      "aphex\n",
      "apnt\n",
      "apo\n",
      "apologetic\n",
      "apologise\n",
      "ap"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 67599 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = count_vector.get_feature_names_out()\n",
    "for feature_name in feature_names:\n",
    "    print(feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd7a980",
   "metadata": {},
   "source": [
    "Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d84c029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:49:00.559766Z",
     "start_time": "2023-09-22T12:49:00.484777Z"
    }
   },
   "outputs": [],
   "source": [
    "x=x_counts.toarray()\n",
    "y=data.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782467b7",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0b9bd84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:49:25.276013Z",
     "start_time": "2023-09-22T12:49:25.259907Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "L=LabelEncoder()\n",
    "y=L.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e499d650",
   "metadata": {},
   "source": [
    "Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92f3d996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:49:54.603522Z",
     "start_time": "2023-09-22T12:49:54.384247Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(x,y,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32b67b6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:49:59.944077Z",
     "start_time": "2023-09-22T12:49:59.927522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4454, 8912)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9343ea58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:50:04.992933Z",
     "start_time": "2023-09-22T12:50:04.984520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 8912)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3178f4b",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f8aea05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:50:25.408914Z",
     "start_time": "2023-09-22T12:50:23.853485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9820466786355476\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       955\n",
      "           1       0.99      0.88      0.93       159\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.99      0.94      0.96      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(\"Accuracy Score:\",accuracy_score(Y_test,Y_pred))\n",
    "print(\"Classification report\",classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b7e0350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:50:40.764167Z",
     "start_time": "2023-09-22T12:50:40.724548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "row_0          \n",
       "0      954    1\n",
       "1       19  140"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a7f2f",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4c4f122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:51:21.154028Z",
     "start_time": "2023-09-22T12:51:07.265658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9694793536804309\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       955\n",
      "           1       0.93      0.86      0.89       159\n",
      "\n",
      "    accuracy                           0.97      1114\n",
      "   macro avg       0.95      0.92      0.94      1114\n",
      "weighted avg       0.97      0.97      0.97      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy Score:\",accuracy_score(Y_test,y_pred))\n",
    "print(\"Classification report\",classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9a2eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:51:21.226986Z",
     "start_time": "2023-09-22T12:51:21.226986Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b040b2",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7ffed17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:52:09.969869Z",
     "start_time": "2023-09-22T12:51:40.683890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9748653500897666\n",
      "Classification report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       955\n",
      "           1       1.00      0.82      0.90       159\n",
      "\n",
      "    accuracy                           0.97      1114\n",
      "   macro avg       0.99      0.91      0.94      1114\n",
      "weighted avg       0.98      0.97      0.97      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier(random_state=42)\n",
    "model2.fit(X_train, Y_train)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "print(\"Accuracy Score:\",accuracy_score(Y_test,y_pred2))\n",
    "print(\"Classification report\",classification_report(Y_test,y_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c857b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T12:52:10.018160Z",
     "start_time": "2023-09-22T12:52:10.018160Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(Y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8697648d",
   "metadata": {},
   "source": [
    "So from above machine learning analysis we conclude that Logistic Regression with 98% is best for Spam detection"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
